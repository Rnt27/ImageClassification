{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_Training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei0nOH_z-kPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/train')\n",
        "test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z76vUMup_WTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViPMD63lzL0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy.special\n",
        "from scipy.special import softmax\n",
        "from math import log\n",
        "class ANN:\n",
        "    def __init__(self, inputnodes, hiddennodes1,hiddennodes2, outputnodes, learningrate):\n",
        "        self.inodes = inputnodes\n",
        "        self.hnodes1 = hiddennodes1\n",
        "        self.hnodes2 = hiddennodes2\n",
        "        self.onodes = outputnodes\n",
        "        self.lr = learningrate\n",
        "    \n",
        "        \n",
        "        # creat initial random weights\n",
        "        self.wih = np.random.normal(0.0, pow(self.hnodes1, -0.5), (self.hnodes1, self.inodes))\n",
        "        self.whh = np.random.normal(0.0, pow(self.hnodes2, -0.5), (self.hnodes2, self.hnodes1))\n",
        "        self.who = np.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes2))\n",
        "        \n",
        "        # Create Activation Functions\n",
        "        self.sigmoid_act_funct = lambda x: scipy.special.expit(x)\n",
        "        self.relu_act_funct = lambda x: np.maximum(0, x)\n",
        "        self.leakyrelu_act_funct = lambda x: np.where(x > 0, x, x * 0.01)\n",
        "        # Actovation Funvtion for output layer\n",
        "        self.softmax_act_funct = lambda x: softmax(x)\n",
        "        pass\n",
        "    # Softmax\n",
        "    def softmax(X):\n",
        "        exps = np.exp(X - np.max(X))\n",
        "        return exps / np.sum(exps)\n",
        "        pass\n",
        "    # SoftMax Corros Entropy\n",
        "    def softmax_cross_entropy(self, actual, predicted):\n",
        "        sum_score = 0.0\n",
        "        for i in range(len(actual)):\n",
        "            for j in range(len(actual[i])):\n",
        "                sum_score += actual[i][j] * log(1e-9 + predicted[i][j])\n",
        "                mean_sum_score = 1.0 / len(actual) * sum_score\n",
        "                return -mean_sum_score\n",
        "            pass\n",
        "        pass\n",
        "    \n",
        "    def train(self, inputs_list, targets_list):\n",
        "        # There are two main parts in trainin 1. Feedforward that we did for query function as well, 2. backpropagation\n",
        "        # convert inputs and targets list in 2d array\n",
        "        inputs =  np.array(inputs_list, ndmin=2).T\n",
        "        targets = np.array(targets_list, ndmin=2).T\n",
        "        \n",
        "        # 1. Feedforward\n",
        "        # matreix multiplication for caclulatin WI into hidden layer\n",
        "        h_input1 = np.dot(self.wih, inputs)\n",
        "        \n",
        "        h_output_sig1 = self.sigmoid_act_funct(h_input1)\n",
        "        \n",
        "        h_input2 = np.dot(self.whh, h_output_sig1)\n",
        "        \n",
        "        # Calculate activation function for hidden layer\n",
        "        h_output_sig2 = self.sigmoid_act_funct(h_input2)\n",
        "        \n",
        "        #h_output_relu = self.relu_act_funct(h_input1)\n",
        "        #h_output_leakyrelu = self.leakyrelu_act_funct(h_input1)\n",
        "        \n",
        "        # matreix multiplication for caclulatin WI into output layer\n",
        "        o_input = np.dot(self.who, h_output_sig2)\n",
        "        \n",
        "        # Calculate activation function for output layer\n",
        "        #o_output = self.softmax_act_funct(o_input)\n",
        "        \n",
        "        o_output= self.sigmoid_act_funct(o_input)\n",
        "        \n",
        "        # 2. Backpropagation\n",
        "        # first we need to calculate the error for output layer wich we are using SoftMax Cross-Entropy Loss for caclularion\n",
        "        o_error =  targets - o_output \n",
        "        #o_error = self.softmax_cross_entropy( o_output, targets)\n",
        "        #o_error = np.sum(np.nan_to_num(-targets*np.log(o_output) - (1-targets)*np.log(1-o_output)))\n",
        "        \n",
        "        # scound we need to calculate hidden layer error that is the output_errors, split by weights,\n",
        "        # recombined at hidden nodes\n",
        "\n",
        "        h_error2 = np.dot(self.who.T, o_error) #  /N\n",
        "        \n",
        "        h_error1 = np.dot(self.whh.T, h_error2)\n",
        "        \n",
        "        ## update the weights for the links between the hidden and output layers\n",
        "        self.who += self.lr * np.dot((o_error * o_output * (1.0 - o_output)), np.transpose(h_output_sig2))\n",
        "        \n",
        "        # update the weights for the links between the two hidden layers\n",
        "        self.whh += self.lr * np.dot((h_error2 * h_output_sig2 * (1.0 - h_output_sig2)), np.transpose(h_output_sig1))\n",
        "        \n",
        "        \n",
        "        # update the weights for the links between the input and hidden layers\n",
        "        self.wih += self.lr * np.dot((h_error1 * h_output_sig1 * (1.0 - h_output_sig1)), np.transpose(inputs))\n",
        "        return o_error\n",
        "        \n",
        "        #print(\"\\nEpoch %d complete\\tLoss: %f\\n\"%(o_error))\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    # The query() function takes the input to a neural network and returns the networkâ€™s output.we need to pass the input signals from the\n",
        "    # input layer of nodes, through the hidden layer and out of the final output layer.\n",
        "    def query(self, inputs_list):\n",
        "        # convert inputs list into 2d array\n",
        "        inputs = np.array(inputs_list, ndmin=2).T\n",
        "        \n",
        "        # matreix multiplication for caclulatin WI into hidden layer \n",
        "        h_input1 = np.dot(self.wih, inputs)\n",
        "        \n",
        "        h_output_sig1 = self.sigmoid_act_funct(h_input1)\n",
        "        \n",
        "        h_input2 = np.dot(self.whh, h_output_sig1)\n",
        "        \n",
        "        # Calculate activation function for hidden layer \n",
        "        h_output_sig2 = self.sigmoid_act_funct(h_input2)\n",
        "        #h_output_relu = self.relu_act_funct(h_input1)\n",
        "        #h_output_leakyrelu = self.leakyrelu_act_funct(h_input1)\n",
        "        \n",
        "        ## matreix multiplication for caclulatin WI into output layer\n",
        "        o_input = np.dot(self.who, h_output_sig2)\n",
        "        \n",
        "        # Calulate activation fumction for output layer \n",
        "        #o_output_softmax = self.sigmoid_act_funct(o_input)\n",
        "        o_output = self.softmax_act_funct(o_input)\n",
        "        \n",
        "        return o_output_softmax\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp8rmROI-b0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of input, hidden and output nodes\n",
        "input_nodes = 3072\n",
        "hidden_nodes1 = 1000\n",
        "hidden_nodes2 = 100\n",
        "output_nodes = 10\n",
        "# learning rate\n",
        "learning_rate = 0.01\n",
        "\n",
        "#ValueError: operands could not be broadcast together with shapes (10,50,250) (1,10,25000)\n",
        "#ValueError: shapes (10,250) and (50,25000) not aligned: 250 (dim 1) != 50 (dim 0)\n",
        "#ValueError: shapes (50,300) and (300,3072,1) not aligned: 300 (dim 1) != 3072 (dim 1)\n",
        "#ValueError: operands could not be broadcast together with shapes (10,50,1) (10,25000,1)\n",
        "\n",
        "# create instance of neural network\n",
        "n = ANN(input_nodes,hidden_nodes1,hidden_nodes2, output_nodes,\n",
        "learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxSqfQzt--6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL06XCB7wXcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train the neural network\n",
        "epoches = 10\n",
        "for i in range(epoches):\n",
        "  for inedx, row in train.iterrows():\n",
        "    #all_value = row #j.split('\\t')\n",
        "  # scale and shift the inputs\n",
        "    inputs = (np.asfarray(row[:-1]) / 255.0 * 0.99) + 0.01\n",
        "  # create the target output values (all 0.01, except the desired label which is 0.99)\n",
        "    targets = np.zeros(output_nodes) + 0.01\n",
        "  # train[:, -1] is the target label for this record\n",
        "    targets[row[-1:].astype(int)] = 0.99\n",
        "    n.train(inputs, targets)\n",
        "  #print(\"\\nEpoch %d complete\\tLoss: %f\\n\"% (o_error[0]))\n",
        "pass\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86IpJ4YJ_CEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obnUkohTwWw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluation\n",
        "eval = []\n",
        "# go through all the records in the test data set\n",
        "#testtarg = list(row[-1:])\n",
        "#print(type(testtarg))\n",
        "\n",
        "for index, row in test.iterrows():\n",
        "  #for i in testtarg: #range(len(row[-1:])):\n",
        "  correct_label = row[-1:].astype(int) #np.array.row[-1:] #test[:, -1].astype(int)\n",
        "  #print(correct_label)\n",
        "  #correcy_label.astype(int64)\n",
        "  #print(type(correct_label))\n",
        "#for j in test[:, :-1]:\n",
        "  # scale and shift the inputs\n",
        "  inputs = (np.asfarray(row[:-1]) / 255.0 * 0.99) + 0.01\n",
        "  #print(type(inputs))\n",
        "  # query the network\n",
        "  outputs = n.query(inputs)\n",
        "  #print(type(outputs))\n",
        "  # the index of the highest value corresponds to the label\n",
        "  label = np.argmax(outputs)\n",
        "  #print(label)\n",
        "# append correct or incorrect to list\n",
        "  if (label == correct_label.any()):\n",
        "    eval.append(1)\n",
        "  else:\n",
        "    eval.append(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av6d4YcX_oin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Accuracy\n",
        "ACC = np.asarray(eval)\n",
        "print (\"Acuracy = \", ACC.sum() / ACC.size * 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwblodyjSiiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}